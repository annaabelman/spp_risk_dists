---
title: 'Set up IUCN extinction risk trends'
author: "*Compiled on `r date()` by `r Sys.info()['user']`*"
output: 
  html_document:
    code_folding: hide
    toc: true
    toc_depth: 3
    toc_float: yes
    number_sections: true
    theme: cerulean
    highlight: haddock
    includes: 
      in_header: '~/github/src/templates/ohara_hdr.html'
  pdf_document:
    toc: true
---

``` {r setup, echo = TRUE, message = FALSE, warning = FALSE}

knitr::opts_chunk$set(fig.width = 6, fig.height = 4, fig.path = 'Figs/',
                      echo = TRUE, message = FALSE, warning = FALSE)


source('https://raw.githubusercontent.com/oharac/src/master/R/common.R')
  ### includes library(tidyverse); library(stringr); 
  ### dir_M points to ohi directory on Mazu; dir_O points to home dir on Mazu

dir_git <- here()


### provenance tracking
# library(provRmd); prov_setup()

source(file.path(dir_git, '_setup/common_fxns.R'))

```

# Summary

Determine IUCN extinction risk trends for marine species by regressing time series assessments against population trends.  This will also be explored for regionally assessed species.

# Data Sources

* IUCN API:  IUCN. (2019). The IUCN Red List of Threatened Species. Version 2019-2. 
* Marine Ecoregions of the World: Spalding, M. D., Fox, H. E., Allen, G. R., Davidson, N., Ferdaña, Z. A., Finlayson, M. A. X., … others. (2007). Marine ecoregions of the world: A bioregionalization of coastal and shelf areas. BioScience, 57(7), 573–583.

# Methods

## Get IUCN historical assessments for IUCN marine species

This process is accomplished in `1_set_up_iucn_risk.Rmd` and `2_set_up_iucn_risk_regional.Rmd`.  Resulting timeseries of historical assessments are available in `data/iucn_risk_timeseries_2017-3.csv` and `data/iucn_risk_ts_rgn_2017-3.csv` (or with updated version numbers as applicable).

## Get all population trends for assessed marine species

Both global and regional trends are gleaned from the API.  First, get the narratives and save them for future use.  Then pull the trend column (stable, increasing, decreasing, unknown).

``` {r get_global_narratives}

spp_narr_file <- file.path(dir_o_anx, 'iucn',
                           sprintf('spp_narrs_from_iucn_%s.csv', api_version))

if(!file.exists(spp_narr_file)) {
  
  spp_risk_file <- file.path(dir_data,
                             sprintf('iucn_risk_current_%s.csv', api_version))

  ### Filter to just the valid species and get narratives.  The cols_only bit
  ### is to prevent it from reading it as a double and failing because of scientific notation.
  spp_ids_valid <- read_csv(spp_risk_file, col_types = cols_only(iucn_sid = 'i')) %>%
    filter(!is.na(iucn_sid)) %>%
    .$iucn_sid %>%
    unique()
  
  ### /api/v3/species/narrative/id/:id?token='YOUR TOKEN'
  spp_narr_url <- 'http://apiv3.iucnredlist.org/api/v3/species/narrative/id/%s?token=%s'
  
  for(i in seq_along(spp_ids_valid)) { # i <- 1
    spp_id <- spp_ids_valid[i]
    tmp_narr_file <- file.path(dir_o_anx, 'tmp', 
                              sprintf('narr_tmp_%s.csv', spp_id))
    if(!file.exists(tmp_narr_file)) {
      cat_msg(i, ' Trying ', spp_id, '\n')
      spp_narr_tmp <- get_from_api(spp_narr_url, spp_id, api_key, delay = 0)
      write_csv(spp_narr_tmp, tmp_narr_file)
    } else {
      message('File exists: ', basename(tmp_narr_file))
    }
  }

  tmp_narr_files <- list.files(file.path(dir_o_anx, 'tmp'),
                               pattern = 'narr_tmp',
                               full.names = TRUE)
  
  spp_narr <- mclapply(tmp_narr_files, 
                       FUN = function(x) {
                         read_csv(x, col_types = cols(.default = 'c'))
                         }, mc.cores = 16) %>%
    bind_rows() %>%
    setNames(str_replace(names(.), 'result.', '')) %>%
    select(-name, iucn_sid = species_id) %>%
    mutate(iucn_sid = as.integer(iucn_sid))
  
  write_csv(spp_narr, spp_narr_file)
}
  
```

``` {r}
    
spp_narr_rgn_file <- file.path(dir_o_anx, 'iucn',
                           sprintf('spp_rgn_narrs_from_iucn_%s.csv', api_version))

if(!file.exists(spp_narr_rgn_file)) {
  
  spp_risk_file <- file.path(dir_data,
                             sprintf('iucn_risk_rgn_current_%s.csv', api_version))

  ### Filter to just the valid species and get narratives.  The cols_only bit
  ### is to prevent it from reading it as a double and failing because of scientific notation.
  spp_ids_valid <- read_csv(spp_risk_file, col_types = cols_only(iucn_sid = 'i', iucn_rgn = 'c')) %>%
    filter(!is.na(iucn_sid)) %>%
    distinct()
  
  ### /api/v3/species/narrative/id/:id/region/:region_identifier?token='YOUR TOKEN'
  spp_narr_url <- 'http://apiv3.iucnredlist.org/api/v3/species/narrative/id/%s/region/RGN_ID?token=%s'
  
  for(i in 1:nrow(spp_ids_valid)) { # i <- 1
    spp_id <- spp_ids_valid$iucn_sid[i]
    rgn_id <- spp_ids_valid$iucn_rgn[i]
    tmp_narr_file <- file.path(dir_o_anx, 'tmp', 
                              sprintf('narr_rgn_tmp_%s_%s.csv', spp_id, rgn_id))
    if(!file.exists(tmp_narr_file)) {
      cat_msg(i, 'of', nrow(spp_ids_valid), ': Trying spp', spp_id, 'from', rgn_id, '\n')
      spp_narr_rgn_url <- spp_narr_url %>% str_replace('RGN_ID', rgn_id)
    
      spp_narr_tmp <- get_from_api(spp_narr_rgn_url, spp_id, api_key, delay = 0)
      write_csv(spp_narr_tmp, tmp_narr_file)
    } else {
      message('File exists: ', basename(tmp_narr_file))
    }
  }
  
  tmp_narr_files <- list.files(file.path(dir_o_anx, 'tmp'),
                               pattern = 'narr_rgn_tmp',
                               full.names = TRUE)
  
  spp_narr <- mclapply(tmp_narr_files, 
                       FUN = function(x) {
                         read_csv(x, col_types = cols(.default = 'c'))
                         }, mc.cores = 16) %>%
    bind_rows() %>%
    setNames(str_replace(names(.), 'result.', '')) %>%
    select(-name, iucn_sid = species_id, iucn_rgn = region_identifier) %>%
    mutate(iucn_sid = as.integer(iucn_sid))
  
  write_csv(spp_narr, spp_narr_rgn_file)
}
```

``` {r}

trends_file <- file.path(dir_setup, 'int/trend_calcs',
                         sprintf('iucn_risk_ts_and_trends_%s.csv', api_version))

spp_trend_all <- read_csv(spp_narr_file) %>%
  mutate(iucn_rgn = 'global') %>%
  bind_rows(read_csv(spp_narr_rgn_file)) %>%
  select(iucn_sid, iucn_rgn, pop_trend = populationtrend) %>%
  distinct()

write_csv(spp_trend_all, trends_file)

```


## Regress species with multiple recent historic assessments against population trends

From data gathered in the execution of SPP v2017, collect species data on past assessments (category) and population trend.  Combine and save.  Note that trend has to be assumed to be related to the most recent assessment only - not included in historical assessment API call.  We will need both a text description of trend (i.e. stable, increasing, or decreasing) and multiple assessments.

For this analysis we will focus only on assessments performed since 1991, the year of v1.0 Red List.

``` {r gather_data_clip_from_1991}

spp_risk_ts_file <- file.path(dir_data,
                              sprintf('iucn_risk_timeseries_%s.csv', api_version))
spp_risk_rgn_ts_file <- file.path(dir_data,
                              sprintf('iucn_risk_ts_rgn_%s.csv', api_version))

spp_risk_ts <- read_csv(spp_risk_ts_file) %>%
  mutate(iucn_rgn = 'global') %>%
  bind_rows(read_csv(spp_risk_rgn_ts_file) %>%
              rename(cat_ts = rgn_cat_ts, cat_ts_score = rgn_cat_ts_score))

cat_trend_91 <- read_csv(trends_file) %>%
  left_join(spp_risk_ts, by = c('iucn_sid', 'iucn_rgn')) %>%
  distinct() %>%
  filter(year >= 1991 & !is.na(cat_ts_score) & !is.na(pop_trend)) %>%
  group_by(iucn_sid, iucn_rgn) %>%
  mutate(n_assess = n()) %>%
  ungroup()

lm_91 <- cat_trend_91 %>%
  filter(n_assess >= 2) %>%
  group_by(iucn_sid, iucn_rgn) %>%
  do(calc_trend = lm( cat_ts_score ~ year, data = .)[['coefficients']][['year']]) %>%
  mutate(calc_trend = round(calc_trend, 5))

trend_91 <- cat_trend_91 %>%
  filter(n_assess > 1) %>%
  group_by(iucn_sid, iucn_rgn) %>%
  summarize(years  = paste(year, collapse = ', '),
            cat_ts = paste(cat_ts, collapse = ', '),
            scores = paste(cat_ts_score, collapse = ', '),
            pop_trend_desc = first(pop_trend)) %>%
  ungroup() %>%
  left_join(lm_91, by = c('iucn_sid', 'iucn_rgn'))

write_csv(trend_91, file.path(dir_setup, 'int/trend_calcs/trend_lm_vs_pop_91.csv'))

DT::datatable(trend_91)
```

``` {r gather_data_clip_from_2001}

cat_trend_01 <- read_csv(trends_file) %>%
  left_join(spp_risk_ts, by = c('iucn_sid', 'iucn_rgn')) %>%
  distinct() %>%
  filter(year >= 2001 & !is.na(cat_ts_score) & !is.na(pop_trend)) %>%
  group_by(iucn_sid, iucn_rgn) %>%
  mutate(n_assess = n()) %>%
  ungroup()

lm_01 <- cat_trend_01 %>%
  filter(n_assess >= 2) %>%
  group_by(iucn_sid, iucn_rgn) %>%
  do(calc_trend = lm( cat_ts_score ~ year, data = .)[['coefficients']][['year']]) %>%
  mutate(calc_trend = round(calc_trend, 5))

trend_01 <- cat_trend_01 %>%
  filter(n_assess > 1) %>%
  group_by(iucn_sid, iucn_rgn) %>%
  summarize(years  = paste(year,   collapse = ', '),
            cat_ts = paste(cat_ts, collapse = ', '),
            scores = paste(cat_ts_score, collapse = ', '),
            pop_trend_desc = first(pop_trend)) %>%
  ungroup() %>%
  left_join(lm_01, by = c('iucn_sid', 'iucn_rgn'))

write_csv(trend_01, file.path(dir_setup, 'int/trend_calcs/trend_lm_vs_pop_01.csv'))

DT::datatable(trend_01)

```

Note that the category scores are higher for higher-risk assessments; so a decreasing population should result in an increasing risk score and vice versa.

``` {r explore_rels}

trend_91 <- read_csv(file.path(dir_setup, 'int/trend_calcs/trend_lm_vs_pop_91.csv')) %>%
  filter(!is.na(pop_trend_desc)) %>%
  mutate(pop_trend = case_when(pop_trend_desc == 'decreasing' ~ -1,
                               pop_trend_desc == 'increasing' ~  1,
                               pop_trend_desc == 'stable'     ~  0,
                               TRUE                           ~ NA_real_))
  ### NOTE: here we're coding the trend in *population* not risk.

trend_regr_91 <- lm(calc_trend ~ pop_trend, data = trend_91)

trend_coeffs_91 <- summary(trend_regr_91)


### BASED ON FILTERING SINCE 1991 (IUCN Red List v1.0)
# lm(formula = calc_trend ~ pop_trend, data = trend_91)
# 
# Residuals:
#       Min        1Q    Median        3Q       Max 
# -0.063883 -0.003883  0.000589  0.005060  0.042017 
# 
# Coefficients:
#               Estimate Std. Error t value Pr(>|t|)    
# (Intercept) -0.0005888  0.0006691   -0.88     0.38    
# pop_trend   -0.0044716  0.0007697   -5.81 2.19e-08 ***
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# 
# Residual standard error: 0.009113 on 219 degrees of freedom
#   (748 observations deleted due to missingness)
# Multiple R-squared:  0.1335,	Adjusted R-squared:  0.1296 
# F-statistic: 33.75 on 1 and 219 DF,  p-value: 2.188e-08  

trend_plot_91 <- ggplot(trend_91, aes(x = pop_trend, y = calc_trend, group = pop_trend)) +
  geom_violin(color = 'grey60', fill = 'grey80') +
  geom_jitter(color = 'blue', alpha = .4) +
  geom_abline(intercept = trend_regr_91$coefficients[['(Intercept)']],
              slope = trend_regr_91$coefficients[['pop_trend']],
              color = 'darkred') +
  scale_x_continuous(breaks = c(-1, 0, 1), labels = c('decreasing', 'stable', 'increasing')) +
  coord_cartesian(ylim = c(-.07, .07)) +
  labs(x = 'text population trend',
       y = 'calculated trend from category time series',
       title = 'Pop trend vs change in assessed risk since 1991') +
  annotate('text', x = 0.1, y = -.06, 
           label = paste0('R^2: ',          round(trend_coeffs_91$r.squared, 5), 
                          '\nslope = ',     round(trend_coeffs_91$coefficients[2, 1], 5),
                          '\np (slope) = ', signif(trend_coeffs_91$coefficients[2, 4], 5)),
           hjust = 0)

print(trend_plot_91)

trend_01 <- read_csv(file.path(dir_setup, 'int/trend_calcs/trend_lm_vs_pop_01.csv')) %>%
  filter(!is.na(pop_trend_desc)) %>%
  mutate(pop_trend = case_when(pop_trend_desc == 'decreasing' ~ -1,
                               pop_trend_desc == 'increasing' ~  1,
                               pop_trend_desc == 'stable'     ~  0,
                               TRUE                           ~ NA_real_))

trend_regr_01 <- lm(calc_trend ~ pop_trend, data = trend_01)

trend_coeffs_01 <- summary(trend_regr_01)

### BASED ON FILTERING SINCE 2001 (v3.1)
# lm(formula = calc_trend ~ pop_trend, data = trend_01)
# 
# Residuals:
#       Min        1Q    Median        3Q       Max 
# -0.063447 -0.003447  0.000661  0.004769  0.042453 
# 
# Coefficients:
#               Estimate Std. Error t value Pr(>|t|)   
# (Intercept) -0.0006608  0.0010513  -0.629  0.53056   
# pop_trend   -0.0041080  0.0012270  -3.348  0.00102 **
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# 
# Residual standard error: 0.01203 on 156 degrees of freedom
#   (686 observations deleted due to missingness)
# Multiple R-squared:  0.06704,	Adjusted R-squared:  0.06106 
# F-statistic: 11.21 on 1 and 156 DF,  p-value: 0.00102

trend_plot_01 <- ggplot(trend_01, aes(x = pop_trend, y = calc_trend, group = pop_trend)) +
  geom_violin(color = 'grey60', fill = 'grey80') +
  geom_jitter(color = 'blue', alpha = .4) +
  geom_abline(intercept = trend_regr_01$coefficients[['(Intercept)']],
              slope = trend_regr_01$coefficients[['pop_trend']],
              color = 'darkred') +
  scale_x_continuous(breaks = c(-1, 0, 1), labels = c('decreasing', 'stable', 'increasing')) +
  coord_cartesian(ylim = c(-.07, .07)) +
  labs(x = 'text population trend',
       y = 'calculated trend from category time series',
       title = 'Pop trend vs change in assessed risk since 2001') +
  annotate('text', x = 0.1, y = -.06, 
           label = paste0('R^2: ',          round(trend_coeffs_01$r.squared, 5), 
                          '\nslope = ',     round(trend_coeffs_01$coefficients[2, 1], 5),
                          '\np (slope) = ', signif(trend_coeffs_01$coefficients[2, 4], 5)),
           hjust = 0)

print(trend_plot_01)

```

One risk category shift would be 0.2 "risk units" (i.e. LC = 0, NT = .2, ..., EX = 1.0); so a decreasing population is likely to increase risk score by about 0.0063 units per year, or on average, take about 30 years to change risk status by one category.  For species on the high and low ends of trends based on time series, about -.06 to +.06, we can read this as changing by as much as one category every three to four years.

## Save species to trend lookup 

The saved trends are based on linear regression of species with at least two non-DD assessments since 1991.  Because of this limitation, only a small number of regionally assessed species contribute to the trend scores.  NOTE:  For OHI, the determination should be made about how to calculate trends - how many assessments must be included? what starting year?

In mapping trends, the mean trend can perhaps be converted more meaningfully into "change in risk category per year" and/or "years per change in risk category".

``` {r save_spp_trends}

### manual values from linear regression:
slope <- trend_coeffs_91$coefficients[2, 1] %>% round(5)
trend_score_lookup <- c('decreasing' = -slope, 'stable' = 0, 'increasing' = slope)

trend_91 <- read_csv(file.path(dir_setup, 'int/trend_calcs/trend_lm_vs_pop_91.csv')) %>%
  select(iucn_sid, iucn_rgn, calc_trend) %>%
  distinct()

trend_df <- read_csv(trends_file) %>%
  left_join(spp_risk_ts, by = c('iucn_sid', 'iucn_rgn')) %>%
  distinct() %>%
  left_join(trend_91, by = c('iucn_sid', 'iucn_rgn')) %>%
  mutate(trend_score  = ifelse(is.na(calc_trend), trend_score_lookup[pop_trend], calc_trend),
         trend_source = case_when(!is.na(calc_trend)  ~ 'lm', 
                                  !is.na(trend_score) ~ 'regr',
                                  TRUE ~ NA_character_)) %>%
  select(iucn_sid, iucn_rgn, pop_trend, trend_score, trend_source) %>%
  distinct()

write_csv(trend_df, file.path(dir_data, sprintf('iucn_trend_by_spp_%s.csv', api_version)))

DT::datatable(trend_df)
```

-----

``` {r prov_footer, results = 'asis'}
# prov_wrapup(commit_outputs = FALSE)
```

